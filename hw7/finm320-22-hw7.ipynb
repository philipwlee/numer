{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two of the functions have one or more places where you are to \"FILL THIS IN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T01:06:43.587087Z",
     "iopub.status.busy": "2022-03-11T01:06:43.586168Z",
     "iopub.status.idle": "2022-03-11T01:06:44.514512Z",
     "shell.execute_reply": "2022-03-11T01:06:44.513724Z",
     "shell.execute_reply.started": "2022-03-11T01:06:43.586986Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T01:06:44.515985Z",
     "iopub.status.busy": "2022-03-11T01:06:44.515506Z",
     "iopub.status.idle": "2022-03-11T01:06:44.522827Z",
     "shell.execute_reply": "2022-03-11T01:06:44.519651Z",
     "shell.execute_reply.started": "2022-03-11T01:06:44.515932Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dynamics:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T01:06:44.525203Z",
     "iopub.status.busy": "2022-03-11T01:06:44.524510Z",
     "iopub.status.idle": "2022-03-11T01:06:44.531766Z",
     "shell.execute_reply": "2022-03-11T01:06:44.531008Z",
     "shell.execute_reply.started": "2022-03-11T01:06:44.525168Z"
    }
   },
   "outputs": [],
   "source": [
    "hw7dynamics=Dynamics()\n",
    "hw7dynamics.S0 = 1\n",
    "hw7dynamics.r = 0.03\n",
    "hw7dynamics.sigma = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T01:06:44.536636Z",
     "iopub.status.busy": "2022-03-11T01:06:44.536008Z",
     "iopub.status.idle": "2022-03-11T01:06:44.542499Z",
     "shell.execute_reply": "2022-03-11T01:06:44.541149Z",
     "shell.execute_reply.started": "2022-03-11T01:06:44.536601Z"
    }
   },
   "outputs": [],
   "source": [
    "class Contract:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T01:06:44.544225Z",
     "iopub.status.busy": "2022-03-11T01:06:44.543796Z",
     "iopub.status.idle": "2022-03-11T01:06:44.550280Z",
     "shell.execute_reply": "2022-03-11T01:06:44.549243Z",
     "shell.execute_reply.started": "2022-03-11T01:06:44.544192Z"
    }
   },
   "outputs": [],
   "source": [
    "hw7contract=Contract() \n",
    "hw7contract.K = 1.1 \n",
    "hw7contract.T = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T01:06:44.552919Z",
     "iopub.status.busy": "2022-03-11T01:06:44.552298Z",
     "iopub.status.idle": "2022-03-11T01:06:44.558428Z",
     "shell.execute_reply": "2022-03-11T01:06:44.557578Z",
     "shell.execute_reply.started": "2022-03-11T01:06:44.552881Z"
    }
   },
   "outputs": [],
   "source": [
    "class MC:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T01:06:44.561512Z",
     "iopub.status.busy": "2022-03-11T01:06:44.560391Z",
     "iopub.status.idle": "2022-03-11T01:06:44.569525Z",
     "shell.execute_reply": "2022-03-11T01:06:44.568589Z",
     "shell.execute_reply.started": "2022-03-11T01:06:44.561299Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hw7MC=MC()\n",
    "hw7MC.M = 100000 # Number of paths  \n",
    "hw7MC.N = 4     # Number of time periods  \n",
    "hw7MC.seed = 0  # Seeding the random number generator with a specified number helps make the calculations reproducible\n",
    "\n",
    "hw7MC.algorithm = 'value'   \n",
    "#'value' for Value-based approach (Longstaff-Schwartz) -- problem 1\n",
    "#'policy' for Policy optimization -- problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T01:06:44.571723Z",
     "iopub.status.busy": "2022-03-11T01:06:44.571344Z",
     "iopub.status.idle": "2022-03-11T01:06:44.578815Z",
     "shell.execute_reply": "2022-03-11T01:06:44.578017Z",
     "shell.execute_reply.started": "2022-03-11T01:06:44.571693Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for Policy optimization approach, problem 2\n",
    "#\n",
    "# If b<<0 then this function essentially returns nearly 1 if X<a, or nearly 0 if X>a\n",
    "# but with some smoothing of the discontinuity, using a sigmoid function, to help the optimizer\n",
    "\n",
    "def softExercise(X,a,b):\n",
    "    return 1/(1+np.exp(np.minimum(-b*(X-a), 709)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T01:06:44.581843Z",
     "iopub.status.busy": "2022-03-11T01:06:44.580393Z",
     "iopub.status.idle": "2022-03-11T01:06:44.599108Z",
     "shell.execute_reply": "2022-03-11T01:06:44.590585Z",
     "shell.execute_reply.started": "2022-03-11T01:06:44.581803Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for Policy optimization approach, problem 2\n",
    "\n",
    "def negofMCaverageOfExpectedPayouts(coefficients, x, exercisePayoff, continuationPayoff):\n",
    "\n",
    "    p = softExercise(x,*coefficients)    \n",
    "\n",
    "    # p and exercisePayoff and continuationPayoff are all length-M arrays\n",
    "\n",
    "    return -np.sum(p*exercisePayoff + (1-p)*continuationPayoff) # FILL THIS IN\n",
    "\n",
    "## You fill in, what to return.  It should be the negative of the expression inside the max() on the homework sheet.\n",
    "## Need to take the negative because we are calling \"minimize\" but we want to do _maximization_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T01:06:44.602014Z",
     "iopub.status.busy": "2022-03-11T01:06:44.601524Z",
     "iopub.status.idle": "2022-03-11T01:06:44.628572Z",
     "shell.execute_reply": "2022-03-11T01:06:44.627631Z",
     "shell.execute_reply.started": "2022-03-11T01:06:44.601984Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pricer_americanPut_GBM_LSM(contract,dynamics,MC):\n",
    "\n",
    "    np.random.seed(MC.seed)  #seed the random number generator\n",
    "    \n",
    "    r=dynamics.r\n",
    "    sigma=dynamics.sigma\n",
    "    S0=dynamics.S0\n",
    "\n",
    "    K=contract.K\n",
    "    T=contract.T\n",
    "\n",
    "    N=MC.N\n",
    "    M=MC.M\n",
    "    dt=T/N\n",
    "\n",
    "    Z = np.random.randn(M, N)\n",
    "    \n",
    "    paths = S0*np.exp((r-sigma**2/2)*dt*np.tile(np.arange(1,N+1),(M,1))+sigma*np.sqrt(dt)*np.cumsum(Z,axis=1))\n",
    "    \n",
    "    payoffDiscounted = np.maximum(0,K-paths[:,-1])\n",
    "    #This is the payoff (cashflow) along each path,\n",
    "    #discounted to time nn (for nn=N,N-1,...)\n",
    "    #It corresponds to the far right-hand column in each page of the\n",
    "    #Excel worksheet\n",
    "    #I'm initializing it for time nn=N.\n",
    "\n",
    "    #You could make payoffDiscounted\n",
    "    #to be a matrix because it depends on nn.\n",
    "    #But I will just reuse a 1-dimensional array,\n",
    "    #by overwriting the time nn+1 entries at time nn.        \n",
    "    \n",
    "    for nn in np.arange(N-1,0,-1):\n",
    "        continuationPayoffDiscounted = np.exp(-r*dt)*payoffDiscounted\n",
    "        # This is the CONTINUATION payoff (cashflow) along each path,\n",
    "        # discounted to time nn (for nn=N-1,N-2,...)\n",
    "        # It corresponds to the blue column in each page of the Excel worksheet\n",
    "        # Note that payoffDiscounted comes from the previous iteration \n",
    "        # -- which was at time nn+1.  So now we discount back to time nn.\n",
    "\n",
    "        X=paths[:,nn-1]               \n",
    "        exerciseValue = K-X\n",
    "        \n",
    "        if MC.algorithm == 'value': \n",
    "            # This is the value function (Longstaff-Schwartz) approach.  For problem 1\n",
    "\n",
    "            basisfunctions = np.stack([np.ones(M), X, X**2], axis=1) # FILL THIS IN.  You may use np.stack\n",
    "                    # This will be an M-by-3 array containing the basis functions (Same ones as L7.8-7.9, and Excel)\n",
    "            res = sm.OLS(continuationPayoffDiscounted, basisfunctions).fit()\n",
    "            \n",
    "            coefficients = res.params # FILL THIS IN  \n",
    "                    # This will be an array of 3 estimated \"betas\".\n",
    "            \n",
    "            estimatedContinuationValue = basisfunctions  @ coefficients # FILL THIS IN with an array of length M. \n",
    "                    # This is similar to the Red column in Excel\n",
    "            \n",
    "            whichPathsToExercise = (exerciseValue >= np.maximum(estimatedContinuationValue,0))\n",
    "                    #This is a length-M array of Booleans\n",
    "        \n",
    "        elif MC.algorithm == 'policy':\n",
    "            # This is the policy optimization approach to Reinforcement learning.  For problem 2\n",
    "            \n",
    "            (a_opt,b_opt) = scipy.optimize.minimize(\n",
    "                negofMCaverageOfExpectedPayouts,(0,0),args=(X,exerciseValue,continuationPayoffDiscounted),method='Nelder-Mead').x\n",
    "                #Chose Nelder-Mead optimizer because it is generating reasonable results with minimal coding effort\n",
    "                #But gradient methods, done properly, usually run faster\n",
    "    \n",
    "            whichPathsToExercise = softExercise(X,a_opt,b_opt)>0.5\n",
    "                #FILL THIS IN, using the right-hand side of the last equation on the homework sheet \n",
    "                #This obtains the hard exercise decision from the optimized soft exercise function\n",
    "                #It should be a length-M array of Booleans (as it was in the \"value\" approach.  \n",
    "                #But here it comes from the softExercise function)\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Unknown algorithm type')\n",
    "        \n",
    "        \n",
    "        payoffDiscounted[whichPathsToExercise] = exerciseValue[whichPathsToExercise] # FILL THIS IN -- see the \"discounted cashflow along path\" column in Excel \n",
    "        payoffDiscounted[np.logical_not(whichPathsToExercise)] = 0 # FILL THIS IN -- see the \"discounted cashflow along path\" column in Excel\n",
    "\n",
    "    # The time-0 calculation needs no regression\n",
    "    continuationPayoffDiscounted = np.exp(-r*dt)*payoffDiscounted;\n",
    "    estimatedContinuationValue = np.mean(continuationPayoffDiscounted);\n",
    "    putprice = max(K-S0,estimatedContinuationValue);\n",
    "        \n",
    "    return(putprice)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T01:06:44.630745Z",
     "iopub.status.busy": "2022-03-11T01:06:44.630369Z",
     "iopub.status.idle": "2022-03-11T01:06:44.737851Z",
     "shell.execute_reply": "2022-03-11T01:06:44.737077Z",
     "shell.execute_reply.started": "2022-03-11T01:06:44.630713Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1004824264979564"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw7MC.algorithm = 'value'\n",
    "\n",
    "pp = pricer_americanPut_GBM_LSM(hw7contract,hw7dynamics,hw7MC)\n",
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T01:06:44.741366Z",
     "iopub.status.busy": "2022-03-11T01:06:44.740990Z",
     "iopub.status.idle": "2022-03-11T01:06:48.448870Z",
     "shell.execute_reply": "2022-03-11T01:06:48.447629Z",
     "shell.execute_reply.started": "2022-03-11T01:06:44.741327Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10036536397930763"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw7MC.algorithm = 'policy'\n",
    "\n",
    "pp = pricer_americanPut_GBM_LSM(hw7contract,hw7dynamics,hw7MC)\n",
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
